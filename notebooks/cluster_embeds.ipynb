{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from glob import glob\n",
    "import torch\n",
    "import torch_geometric\n",
    "import random\n",
    "import yaml\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils import remove_isolated_nodes\n",
    "from torch import nn\n",
    "from torch_geometric.nn import GCN2Conv\n",
    "from torch_geometric.nn import SAGPooling\n",
    "from torch_geometric.nn import MLP\n",
    "from torch_geometric.nn import AttentiveFP\n",
    "from torch_geometric.nn.aggr import AttentionalAggregation\n",
    "from copy import deepcopy \n",
    "from torch_geometric.nn import GATConv, MessagePassing, global_add_pool\n",
    "from torch.nn import TripletMarginLoss\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_complexes = [\"3gdt\", \"3g1v\", \"3w07\", \"3g1d\", \"1loq\", \"3wjw\", \"2zz1\", \"2zz2\", \"1km3\", \"1x1z\", \n",
    "                     \"6cbg\", \"5j7q\", \"6cbf\", \"4wrb\", \"6b1k\", \"5hvs\", \"5hvt\", \"3rf5\", \"3rf4\", \"1mfi\", \n",
    "                     \"5efh\", \"6csq\", \"5efj\", \"6csr\", \"6css\", \"6csp\", \"5een\", \"5ef7\", \"5eek\", \"5eei\",\n",
    "                     \"3ozt\", \"3u81\", \"4p58\", \"5k03\", \"3ozr\", \"3ozs\", \"3oe5\", \"3oe4\", \"3hvi\", \"3hvj\",\n",
    "                     \"3g2y\", \"3g2z\", \"3g30\", \"3g31\", \"3g34\", \"3g32\", \"4de2\", \"3g35\", \"4de0\", \"4de1\",\n",
    "                     \"2exm\", \"4i3z\", \"1e1v\", \"5jq5\", \"1jsv\", \"1e1x\", \"4bcp\", \"4eor\", \"1b38\", \"1pxp\", \"2xnb\", \"4bco\", \"4bcm\", \"1pxn\", \"4bcn\", \"1h1s\", \"4bck\", \"2fvd\", \"1pxo\", \"2xmy\",\n",
    "                     \"4xoe\", \"5fs5\", \"1uwf\", \"4att\", \"4av4\", \"4av5\", \"4avh\", \"4avj\", \"4avi\", \"4auj\", \"4x50\", \"4lov\", \"4x5r\", \"4buq\", \"4x5p\", \"4css\", \"4xoc\", \"4cst\", \"4xo8\", \"4x5q\",\n",
    "                     \"1gpk\", \"3zv7\", \"1gpn\", \"5bwc\", \"5nau\", \"5nap\", \"1h23\", \"1h22\", \"1e66\", \"4m0e\", \"4m0f\", \"2ha3\", \"2whp\", \"2ha6\", \"2ha2\", \"1n5r\", \"4arb\", \"4ara\", \"5ehq\", \"1q84\",\n",
    "                     \"2z1w\", \"3rr4\", \"1s38\", \"1q65\", \"4q4q\", \"4q4p\", \"4q4r\", \"4kwo\", \"1r5y\", \"4leq\", \"4lbu\", \"1f3e\", \"4pum\", \"4q4s\", \"3gc5\", \"2qzr\", \"4q4o\", \"3gc4\", \"5jxq\", \"3ge7\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/xdisk/twheeler/jgaiser/deepvs2/deepvs/'\n",
    "\n",
    "with open(root + 'config.yaml', 'r') as config_file:\n",
    "    config = yaml.safe_load(config_file) \n",
    "\n",
    "ATOM_LABELS = config['constants']['pocket']['HEAVY_ATOM_LABELS']\n",
    "EDGE_LABELS = config['constants']['pocket']['EDGE_LABELS']\n",
    "INTERACTION_LABELS = config['constants']['pocket']['INTERACTION_LABELS']\n",
    "\n",
    "voxel_label_index = ATOM_LABELS.index('VOXEL')\n",
    "\n",
    "voxel_dir = root + \"data/training_data/graph_data/training_samples/1.0_angstroms/partitions/\"\n",
    "mol_dir = root + 'data/training_data/graph_data/molecules/'\n",
    "\n",
    "sample_col_ft = voxel_dir + \"training_samples_%s.pkl\"\n",
    "mol_ft = mol_dir + \"%s_mol.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mol_dict = {}\n",
    "mol_graph_files = glob(mol_dir + \"*.pkl\")\n",
    "\n",
    "for graph_file in mol_graph_files:\n",
    "    pdb_id = graph_file.split('/')[-1].split('_')[0]\n",
    "    mol_dict[pdb_id] = pickle.load(open(graph_file, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_col = glob(voxel_dir + \"*.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mol_batch(mol_collection, pdb_ids):\n",
    "    return next(iter(DataLoader([mol_collection[x] for x in pdb_ids], \n",
    "                                shuffle=False, \n",
    "                                batch_size = len(pdb_ids))))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([352, 512])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import GATv2Conv\n",
    "from torch_geometric.nn import GCN2Conv\n",
    "\n",
    "def handle_data(batch):\n",
    "    beta = batch.beta/100 \n",
    "    x = torch.hstack((batch.x, beta.unsqueeze(1)))\n",
    "    edge_attr = batch.edge_attr.unsqueeze(1) / 12\n",
    "    return x, batch.edge_index, edge_attr\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, feature_dim, hidden_dim, out_dim, data_transform):\n",
    "        super().__init__()\n",
    "        self.data_transform = data_transform\n",
    "        self.linear1 = torch.nn.Linear(feature_dim, hidden_dim)\n",
    "        \n",
    "        self.conv1 = GCN2Conv(hidden_dim, 0.25)\n",
    "        self.conv2 = GCN2Conv(hidden_dim, 0.25)\n",
    "        self.conv3 = GCN2Conv(hidden_dim, 0.25)\n",
    "\n",
    "        self.dropout = torch.nn.Dropout(p=0.25)\n",
    "        self.batchnorm = torch_geometric.nn.norm.BatchNorm(hidden_dim)\n",
    "        self.linear2 = torch.nn.Linear(hidden_dim, out_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_weights = self.data_transform(data)\n",
    "\n",
    "        x = self.linear1(x)\n",
    "\n",
    "        h = self.conv1(x, x, edge_index, edge_weights)\n",
    "        h = self.batchnorm(h)\n",
    "        h = self.dropout(F.relu(h))\n",
    "\n",
    "        h = self.conv2(h, x, edge_index, edge_weights)\n",
    "        h = self.batchnorm(h)\n",
    "        h = self.dropout(F.relu(h))\n",
    "\n",
    "        h = self.conv3(h, x, edge_index, edge_weights)\n",
    "        h = self.batchnorm(h)\n",
    "        h = self.dropout(F.relu(h))\n",
    "        \n",
    "        o = self.linear2(h)\n",
    "        return h,o\n",
    "\n",
    "voxel_model = GCN(39, 512, 9, data_transform=handle_data)\n",
    "\n",
    "for sample_file in sample_col:\n",
    "    sample_collection = DataLoader(pickle.load(open(sample_file, 'rb')), batch_size=32, shuffle=True)\n",
    "    \n",
    "    for batch in sample_collection:\n",
    "        out = voxel_model(batch)\n",
    "        print(out[0].shape)\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([   0,   64,  152,  393,  481,  592,  667,  863,  934,  967, 1005, 1057,\n",
      "        1116, 1326, 1363, 1438, 1482, 1593, 1802, 1869, 1939, 1986, 2017, 2077,\n",
      "        2115, 2188, 2263, 2510, 2571, 2618, 2814, 2940, 3007])\n",
      "torch.Size([3007, 512])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import AttentiveFP\n",
    "from torch_geometric.nn import GATConv, MessagePassing, global_add_pool\n",
    "\n",
    "class ME(AttentiveFP):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.atom_classifier = nn.Linear(kwargs['hidden_channels'], 512)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
    "        \"\"\"\"\"\"\n",
    "        # Atom Embedding:\n",
    "        x = F.leaky_relu_(self.lin1(x))\n",
    "\n",
    "        h = F.elu_(self.atom_convs[0](x, edge_index, edge_attr))\n",
    "        h = F.dropout(h, p=self.dropout, training=self.training)\n",
    "        x = self.atom_grus[0](h, x).relu_()\n",
    "\n",
    "        for conv, gru in zip(self.atom_convs[1:], self.atom_grus[1:]):\n",
    "            h = F.elu_(conv(x, edge_index))\n",
    "            h = F.dropout(h, p=self.dropout, training=self.training)\n",
    "            x = gru(h, x).relu_()\n",
    "\n",
    "        # Molecule Embedding:\n",
    "        row = torch.arange(batch.size(0), device=batch.device)\n",
    "        edge_index = torch.stack([row, batch], dim=0)\n",
    "\n",
    "        out = global_add_pool(x, batch).relu_()\n",
    "        \n",
    "        for t in range(self.num_timesteps):\n",
    "            h = F.elu_(self.mol_conv((x, out), edge_index))\n",
    "            h = F.dropout(h, p=self.dropout, training=self.training)\n",
    "            out = self.mol_gru(h, out).relu_()\n",
    "\n",
    "        # Predictor:\n",
    "        out = F.dropout(out, p=self.dropout, training=self.training)\n",
    "        return self.atom_classifier(x), self.lin2(out)\n",
    "    \n",
    "mol_model = ME(in_channels=38, \n",
    "               hidden_channels=512, \n",
    "               out_channels=512, \n",
    "               edge_dim=1, \n",
    "               num_layers=3, \n",
    "               num_timesteps=3, \n",
    "               dropout=0.5)\n",
    "\n",
    "for batch in sample_collection:\n",
    "    mol_batch = get_mol_batch(mol_dict, batch.pdb_id)\n",
    "    print(mol_batch.ptr)\n",
    "    out = mol_model(mol_batch)\n",
    "    print(out[0].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCN(\n",
       "  (linear1): Linear(in_features=39, out_features=512, bias=True)\n",
       "  (conv1): GCN2Conv(512, alpha=0.25, beta=1.0)\n",
       "  (conv2): GCN2Conv(512, alpha=0.25, beta=1.0)\n",
       "  (conv3): GCN2Conv(512, alpha=0.25, beta=1.0)\n",
       "  (dropout): Dropout(p=0.25, inplace=False)\n",
       "  (batchnorm): BatchNorm(512)\n",
       "  (linear2): Linear(in_features=512, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "mol_weights = \"/xdisk/twheeler/jgaiser/deepvs2/contrastive_loss_exp/mol_embedder/mol_embedder_holdout_3-20.m\"\n",
    "vox_weights = \"/xdisk/twheeler/jgaiser/deepvs2/contrastive_loss_exp/vox_embedder/vox_embedder_holdout_3-20.m\"\n",
    "\n",
    "mol_model = ME(in_channels=38, \n",
    "               hidden_channels=512, \n",
    "               out_channels=512, \n",
    "               edge_dim=1, \n",
    "               num_layers=3, \n",
    "               num_timesteps=3, \n",
    "               dropout=0.5).to(device)\n",
    "\n",
    "vox_model = GCN(39, 512, 9, data_transform=handle_data).to(device)\n",
    "\n",
    "mol_model.load_state_dict(torch.load(mol_weights))\n",
    "vox_model.load_state_dict(torch.load(vox_weights))\n",
    "\n",
    "mol_model.eval()\n",
    "vox_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap.umap_ as umap\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2, perplexity=30, n_iter=1000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1,  4,  5,  7,  8,  9, 10, 12, 13, 15, 17, 22, 28, 31, 32, 37, 38, 47,\n",
      "        48, 50, 51, 58, 61, 63], device='cuda:0')\n",
      "tensor([ 0,  1,  2,  3,  5,  6,  7, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
      "        22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41,\n",
      "        42, 43, 44, 45, 46, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62,\n",
      "        63], device='cuda:0')\n",
      "[ 1  5  7 10 13 15 17 22 28 31 32 50 51 61 63]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for sample_file in sample_col:\n",
    "        sample_file = pickle.load(open(sample_file, 'rb'))\n",
    "        filtered_sample_graphs = []\n",
    "\n",
    "        for sample_graph in sample_file:\n",
    "            if sample_graph.pdb_id not in holdout_complexes:\n",
    "                filtered_sample_graphs.append(sample_graph)\n",
    "\n",
    "        sample_collection = DataLoader(filtered_sample_graphs, batch_size=64, shuffle=True)\n",
    "        \n",
    "        data_points = None \n",
    "        data_classes = []\n",
    "\n",
    "        for batch_i, vox_batch in enumerate(sample_collection):\n",
    "            vox_batch = vox_batch.to(device)\n",
    "            mol_batch = get_mol_batch(mol_dict, vox_batch.pdb_id).to(device)\n",
    "            voxel_indices = torch.where(vox_batch.x[:, voxel_label_index]==1)[0]\n",
    "            \n",
    "            interaction_indices = torch.where(torch.sum(vox_batch.y, dim=1))[0]\n",
    "            true_contacts = torch.where(vox_batch.contact_map != -1)[0]\n",
    "            \n",
    "            print(interaction_indices)\n",
    "            print(true_contacts)\n",
    "            \n",
    "            true_contacts = np.intersect1d(interaction_indices.cpu().detach().numpy(), \n",
    "                                           true_contacts.cpu().detach().numpy())\n",
    "            \n",
    "            contact_indices = vox_batch.contact_map + mol_batch.ptr[:-1]\n",
    "            contact_indices = contact_indices[true_contacts]\n",
    "            \n",
    "            vox_out,_ = vox_model(vox_batch)\n",
    "            mol_out,_ = mol_model(mol_batch)\n",
    "            \n",
    "            vox_pos = vox_out[voxel_indices]\n",
    "            mol_pos = mol_out[contact_indices]\n",
    "            \n",
    "            for sample_val in vox_batch.y[interaction_indices]:\n",
    "                sample_class = np.random.choice(torch.where(sample_val==1)[0].cpu().detach().numpy())\n",
    "                data_classes.append(sample_class)  \n",
    "            \n",
    "            if data_points == None:\n",
    "                data_points = vox_out[interaction_indices]\n",
    "                continue\n",
    "            \n",
    "            data_points = torch.vstack((data_points, vox_out[interaction_indices]))\n",
    "            \n",
    "#             mol_out,_ = mol_model(mol_batch)\n",
    "        \n",
    "        break\n",
    "    \n",
    "# data = np.array(data_points.cpu().detach())\n",
    "# labels = np.array(data_classes)\n",
    "\n",
    "# # reducer = umap.UMAP(n_neighbors=5, n_components=2, metric='euclidean')\n",
    "# # embedding = reducer.fit_transform(data)\n",
    "# embedding = tsne.fit_transform(data)\n",
    "        \n",
    "# plt.scatter(embedding[:, 0], embedding[:, 1], c=labels, cmap='viridis')\n",
    "# plt.colorbar()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCN(\n",
       "  (linear1): Linear(in_features=39, out_features=512, bias=True)\n",
       "  (conv1): GCN2Conv(512, alpha=0.25, beta=1.0)\n",
       "  (conv2): GCN2Conv(512, alpha=0.25, beta=1.0)\n",
       "  (conv3): GCN2Conv(512, alpha=0.25, beta=1.0)\n",
       "  (dropout): Dropout(p=0.25, inplace=False)\n",
       "  (batchnorm): BatchNorm(512)\n",
       "  (linear2): Linear(in_features=512, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "mol_model = ME(in_channels=38, \n",
    "               hidden_channels=512, \n",
    "               out_channels=512, \n",
    "               edge_dim=1, \n",
    "               num_layers=3, \n",
    "               num_timesteps=3, \n",
    "               dropout=0.5).to(device)\n",
    "\n",
    "vox_model = GCN(39, 512, 9, data_transform=handle_data).to(device)\n",
    "\n",
    "mol_model.load_state_dict(torch.load(mol_weights))\n",
    "vox_model.load_state_dict(torch.load(vox_weights))\n",
    "\n",
    "mol_model.eval()\n",
    "vox_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.1374, 0.0000,\n",
      "        0.0000, 5.3852, 0.6956, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.1381, 1.4832, 0.0000,\n",
      "        3.6136, 0.0000, 0.0000, 2.8386, 3.4378, 0.0000, 0.1881, 4.5349, 0.8032,\n",
      "        0.0000, 0.0000, 0.0000, 0.2161, 0.0000, 3.3003, 0.0000, 0.0000, 0.0000,\n",
      "        2.8792, 0.0000, 1.7987, 0.0000, 0.0000, 0.0000, 0.0000, 1.4856, 0.0000,\n",
      "        0.7792, 0.0000, 5.3847, 0.2224, 4.6548, 0.0000, 0.0000, 3.6778, 2.7847,\n",
      "        0.0000, 0.0000, 0.1906, 0.0000, 0.0000, 0.0000, 2.0430, 1.1994, 0.0000,\n",
      "        1.4317, 0.0000, 0.0000, 2.5312, 0.0000, 0.6340, 0.0000, 0.0000, 0.0000,\n",
      "        0.6127, 0.8837, 3.2478, 0.0000, 1.2316, 0.5463, 1.4025, 0.0000, 0.0000,\n",
      "        0.0000, 1.0905, 0.0000, 0.5936, 0.0000, 8.7095, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 2.2545, 0.7675, 0.0000, 0.0000, 0.0000, 0.9533, 1.4715, 3.0845,\n",
      "        5.6001, 0.0000, 0.0000, 0.0000, 2.8477, 2.6621, 0.0000, 0.0000, 0.9167,\n",
      "        1.7597, 0.0000, 0.9313, 0.0000, 3.1039, 0.0000, 0.0000, 7.5684, 4.5388,\n",
      "        0.0000, 0.0000, 0.0000, 4.1001, 1.9060, 0.0000, 0.0000, 0.1552, 1.0653,\n",
      "        0.0000, 0.0000, 0.0000, 2.9306, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        5.2769, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6789,\n",
      "        0.0000, 0.0000, 0.0000, 6.2546, 0.0000, 0.0000, 0.0000, 0.0000, 1.3637,\n",
      "        2.4242, 0.0000, 0.0000, 2.4837, 2.3000, 0.0000, 0.0000, 0.0000, 5.0636,\n",
      "        0.0000, 1.5774, 0.0000, 0.0000, 0.0000, 5.2058, 0.4911, 0.0000, 4.1249,\n",
      "        8.8589, 0.0000, 0.0000, 0.0000, 0.0000, 0.3739, 0.1142, 7.3750, 0.4652,\n",
      "        1.2163, 7.2146, 0.0000, 0.0000, 6.8541, 0.0000, 1.5910, 9.5473, 0.0000,\n",
      "        8.2938, 0.0000, 4.2065, 0.0000, 0.0000, 2.0829, 0.0000, 0.0000, 0.0000,\n",
      "        4.6451, 0.0000, 0.0000, 0.0000, 0.9952, 0.0000, 0.7614, 5.0840, 2.1543,\n",
      "        0.0000, 0.0000, 0.7892, 2.1865, 4.4097, 0.6059, 0.0000, 0.0000, 1.3113,\n",
      "        0.0000, 0.0000, 0.6120, 0.5751, 0.0000, 0.0000, 0.0000, 2.0793, 0.0000,\n",
      "        0.0000, 0.4178, 0.0000, 0.0000, 0.3870, 1.3445, 0.0000, 0.0000, 2.6992,\n",
      "        0.6025, 0.0000, 0.3053, 8.1221, 0.0000, 0.0000, 0.0000, 2.8329, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 5.6311, 1.7767, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        6.5546, 0.0000, 0.0000, 0.0000, 0.0000, 0.1424, 0.0000, 0.0000, 0.0000,\n",
      "        0.6366, 2.9848, 0.9363, 0.0000, 0.2957, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.6673, 0.0000, 0.0000, 4.3571, 0.8946, 1.1446, 2.6887, 0.0000,\n",
      "        0.0000, 2.9721, 0.4048, 0.0000, 2.0534, 6.7758, 2.2609, 0.0000, 0.0000,\n",
      "        0.0000, 2.1504, 0.0000, 0.0000, 0.0000, 0.8418, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 2.9353, 0.0000, 2.5063, 2.2557, 4.6599,\n",
      "        0.5939, 0.0000, 0.0395, 6.1298, 0.0000, 0.0000, 0.0000, 0.0000, 1.6886,\n",
      "        0.0000, 0.0000, 0.0000, 3.0763, 7.2322, 0.0000, 1.9896, 2.9567, 8.2148,\n",
      "        0.7428, 7.9200, 0.0000, 1.5244, 3.3087, 0.0000, 0.0000, 0.0000, 5.9956,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 4.6816, 0.0000,\n",
      "        0.0897, 0.0000, 0.0000, 1.1054, 0.0000, 2.5603, 4.2339, 0.0000, 2.9892,\n",
      "        3.4418, 0.0000, 3.4145, 0.0000, 0.0000, 3.3501, 0.5855, 0.0000, 0.0000,\n",
      "        5.1461, 0.3459, 0.0000, 0.0000, 5.2675, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        1.3666, 0.2068, 1.6878, 0.6115, 0.0000, 0.0000, 0.0000, 9.8021, 0.4579,\n",
      "        1.0906, 0.0000, 0.0000, 0.0000, 2.7572, 2.8895, 0.0000, 3.0924, 0.0000,\n",
      "        0.0000, 4.3128, 2.4930, 0.0000, 0.0000, 1.4616, 1.4618, 0.0000, 0.0000,\n",
      "        0.0000, 0.5481, 0.0630, 0.0000, 1.6630, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0780, 0.4439, 2.0771, 0.0000, 0.0202, 0.0000, 2.6687, 0.0000,\n",
      "        0.0000, 3.7540, 0.9558, 0.0000, 0.5826, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        2.7655, 0.4611, 0.0000, 0.0000, 1.8235, 0.0000, 0.4194, 0.2668, 2.7784,\n",
      "        4.0710, 3.5635, 8.8232, 0.0000, 0.0000, 4.8931, 0.0000, 0.0000, 2.2658,\n",
      "        0.0000, 0.0000, 0.0000, 0.5478, 0.0000, 0.0000, 1.6919, 1.3013, 0.7219,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        1.9391, 1.3511, 0.0000, 0.0000, 0.0000, 0.9836, 0.0000, 0.0000, 0.2967,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 4.3270, 0.0000, 0.0000, 1.4839, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        2.6460, 0.0144, 0.0000, 0.0000, 0.0000, 0.0000, 2.0884, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.8626, 3.7330, 0.0000, 0.0000, 1.2803, 0.0000],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for sample_file in sample_col:\n",
    "        sample_collection = DataLoader(pickle.load(open(sample_file, 'rb')), batch_size=64, shuffle=True)\n",
    "        sample_col_loss = []\n",
    "\n",
    "        for batch_i, vox_batch in enumerate(sample_collection):\n",
    "            vox_batch = vox_batch.to(device)\n",
    "            mol_batch = get_mol_batch(mol_dict, vox_batch.pdb_id).to(device)\n",
    "            voxel_indices = torch.where(vox_batch.x[:, voxel_label_index]==1)[0]\n",
    "\n",
    "            vox_out,_ = vox_model(vox_batch)\n",
    "            mol_out,_ = mol_model(mol_batch)\n",
    "            \n",
    "            print(vox_out[0])\n",
    "            \n",
    "            break\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vs-env",
   "language": "python",
   "name": "vs-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
