{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from glob import glob\n",
    "import torch\n",
    "import torch_geometric\n",
    "import random\n",
    "import yaml\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils import remove_isolated_nodes\n",
    "from torch import nn\n",
    "from torch_geometric.nn import GCN2Conv\n",
    "from torch_geometric.nn import SAGPooling\n",
    "from torch_geometric.nn import MLP\n",
    "from torch_geometric.nn import AttentiveFP\n",
    "from torch_geometric.nn.aggr import AttentionalAggregation\n",
    "from copy import deepcopy \n",
    "from torch_geometric.nn import GATConv, MessagePassing, global_add_pool\n",
    "from torch.nn import TripletMarginLoss\n",
    "import importlib.util\n",
    "from torch_geometric.nn import radius_graph\n",
    "import itertools\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path     = '/xdisk/twheeler/jgaiser/deepvs3/deepvs/'\n",
    "params_path   = root_path + 'params.yaml'\n",
    "config_path   = root_path + 'config.yaml'\n",
    "function_path = root_path + 'code/utils/data_processing_utils.py'\n",
    "\n",
    "def load_class_from_file(file_path):\n",
    "    class_name = file_path.split(\"/\")[-1].split(\".\")[0]\n",
    "    spec = importlib.util.spec_from_file_location(class_name, file_path)\n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(module)\n",
    "    return getattr(module, class_name)\n",
    "\n",
    "\n",
    "def load_function_from_file(file_path):\n",
    "    function_name = file_path.split(\"/\")[-1].split(\".\")[0]\n",
    "    spec = importlib.util.spec_from_file_location(\n",
    "        os.path.basename(file_path), file_path\n",
    "    )\n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "    sys.modules[spec.name] = module\n",
    "    spec.loader.exec_module(module)\n",
    "    return getattr(module, function_name) \n",
    "\n",
    "\n",
    "with open(params_path, \"r\") as param_file:\n",
    "    params = yaml.safe_load(param_file)\n",
    "    \n",
    "with open(config_path, \"r\") as config_file:\n",
    "    config = yaml.safe_load(config_file)\n",
    "\n",
    "mol_graph_ft = params['data_dir'] + config['mol_graph_file_template'] \n",
    "poxel_graph_ft = params['data_dir'] + config['full_pocket_graph_file_template']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.utils import add_self_loops, to_undirected\n",
    "\n",
    "torch.tensor((1,2,3.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  2548.,  78945.,  60011., 126140.,   1062.,   2616.,  13124.,  11344.,\n",
      "          4288.])\n"
     ]
    }
   ],
   "source": [
    "poxel_data = []\n",
    "pdb_ids = []\n",
    "mol_data = {}\n",
    "\n",
    "vox_interaction_count = torch.zeros(9)\n",
    "\n",
    "for g_file in glob(poxel_graph_ft.replace('%s', '*')):\n",
    "    g = pickle.load(open(g_file, 'rb'))\n",
    "    \n",
    "    pdb_id = g_file.split('/')[-1].split('_')[0]\n",
    "    g.pdb_id = pdb_id\n",
    "    vox_interaction_count += torch.sum(g.y, dim=0)\n",
    "        \n",
    "    pdb_ids.append(pdb_id) \n",
    "    poxel_data.append(g)\n",
    "    \n",
    "print(vox_interaction_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g_file in glob(mol_graph_ft.replace('%s', '*')):\n",
    "    pdb_id = g_file.split('/')[-1].split('_')[0]\n",
    "    g = pickle.load(open(g_file, 'rb'))\n",
    "    g.pdb_id = pdb_id\n",
    "    mol_data[pdb_id] = g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'poxel_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [84], line 42\u001b[0m\n\u001b[1;32m     39\u001b[0m mol_train_set \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     40\u001b[0m mol_val_set \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pox_sample \u001b[38;5;129;01min\u001b[39;00m \u001b[43mpoxel_data\u001b[49m:\n\u001b[1;32m     43\u001b[0m     sample_id \u001b[38;5;241m=\u001b[39m pox_sample\u001b[38;5;241m.\u001b[39mpdb_id\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [sample_id \u001b[38;5;129;01min\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m validation_ids]:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'poxel_data' is not defined"
     ]
    }
   ],
   "source": [
    "pdbbind_dict = {}\n",
    "candidate_proteins = []\n",
    "validation_ids = []\n",
    "\n",
    "with open('/xdisk/twheeler/jgaiser/data/pdbbind/index_readme/general/index/INDEX_general_PL_name.2020', 'r') as index_in:\n",
    "    for line_i, line in enumerate(index_in):\n",
    "        if line[0] == '#':\n",
    "            continue\n",
    "        \n",
    "        line_arr = line.rstrip().split('  ')\n",
    "         \n",
    "        if len(line_arr) != 4:\n",
    "             continue\n",
    "                \n",
    "        protein_name = line_arr[-1]\n",
    "        \n",
    "        if protein_name not in pdbbind_dict:\n",
    "            pdbbind_dict[protein_name] = [line_arr[0]]\n",
    "        else:\n",
    "            pdbbind_dict[protein_name].append(line_arr[0])\n",
    "            \n",
    "for k,v in pdbbind_dict.items():\n",
    "    if len(v) >= 10 and len(v) <= 18:\n",
    "        candidate_proteins.append(k)\n",
    "    \n",
    "random.shuffle(candidate_proteins)\n",
    "\n",
    "for k in candidate_proteins:\n",
    "    if sum([len(x) for x in validation_ids]) > 250:\n",
    "        break\n",
    "    \n",
    "    validation_ids.append(pdbbind_dict[k])\n",
    "\n",
    "print(len(validation_ids))\n",
    "\n",
    "pox_train_set = []\n",
    "pox_val_set = []\n",
    "\n",
    "mol_train_set = []\n",
    "mol_val_set = []\n",
    "\n",
    "for pox_sample in poxel_data:\n",
    "    sample_id = pox_sample.pdb_id\n",
    "    \n",
    "    if True in [sample_id in x for x in validation_ids]:\n",
    "        pox_val_set.append(pox_sample)\n",
    "        mol_val_set.append(mol_data[pox_sample.pdb_id])\n",
    "        continue\n",
    "    \n",
    "    pox_train_set.append(pox_sample)\n",
    "    mol_train_set.append(mol_data[pox_sample.pdb_id])\n",
    "    \n",
    "def get_random_batch_pair(set_a, set_b, device='cpu', batch_size=32, min_prob=0.1):\n",
    "    batch_indices = torch.randperm(len(set_a))\n",
    "\n",
    "    poxel_graph_list = []\n",
    "    \n",
    "    for i in batch_indices[:batch_size]:\n",
    "        g = deepcopy(set_a[i])\n",
    "        \n",
    "#         random_prob = random.randrange(int(min_prob*10), 11) / 10\n",
    "#         random_node_indices = torch.randperm(len(g.x))[:int(len(g.x)*random_prob)]\n",
    "#         g.x = g.x[random_node_indices]\n",
    "#         g.pos = g.pos[random_node_indices]\n",
    "        \n",
    "        poxel_graph_list.append(g)\n",
    "        \n",
    "    \n",
    "    batch_a = Batch.from_data_list(poxel_graph_list)\n",
    "    batch_b = Batch.from_data_list([set_b[x] for x in batch_indices[:batch_size]])\n",
    "    return batch_a.to(device), batch_b.to(device)\n",
    "\n",
    "pox_val_data = []\n",
    "mol_val_data = []\n",
    "\n",
    "for target in validation_ids:\n",
    "    target_poxels = []\n",
    "    target_mols = []\n",
    "    \n",
    "    for pdb_id in target:\n",
    "        for poxel_graph in pox_val_set:\n",
    "            if poxel_graph.pdb_id == pdb_id:\n",
    "                g = deepcopy(poxel_graph)\n",
    "        #         poxel_graph_list.append(g)\n",
    "#                 random_prob = random.randrange(int(min_prob*10), 11) / 10\n",
    "#                 random_prob = 0.4\n",
    "#                 random_node_indices = torch.randperm(len(g.x))[:int(len(g.x)*random_prob)]\n",
    "#                 g.x = g.x[random_node_indices]\n",
    "#                 g.pos = g.pos[random_node_indices]\n",
    "                target_poxels.append(g)\n",
    "                \n",
    "        for mol_graph in mol_val_set:\n",
    "            if mol_graph.pdb_id == pdb_id:\n",
    "                target_mols.append(mol_graph)\n",
    "                \n",
    "    pox_val_batch = Batch.from_data_list(target_poxels)\n",
    "    pox_val_data.append(Batch.from_data_list(target_poxels))\n",
    "    mol_val_data.append(Batch.from_data_list(target_mols))\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "for i in range(len(pox_val_data)):\n",
    "    pox_val_data[i] = pox_val_data[i].to(device)\n",
    "    mol_val_data[i] = mol_val_data[i].to(device)\n",
    "    \n",
    "del poxel_data\n",
    "del mol_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/xdisk/twheeler/jgaiser/deepvs3/deepvs//models/weights/ac_classifier_7-16.m'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac_weights = config['active_classifier_weights'] % root_path\n",
    "ac_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sigmoid = nn.Sigmoid()\n",
    "\n",
    "def validate(model, pox_val_data, mol_val_data):\n",
    "    model.eval()\n",
    "    \n",
    "    total_auc_scores = []\n",
    "    total_pos_scores = []\n",
    "    total_neg_scores = []\n",
    "    total_mean_scores = []\n",
    "    all_scores = []\n",
    "    \n",
    "    for i in range(len(pox_val_data)):\n",
    "        print('Evaluating validation target %s' % i)\n",
    "        val_target_batch = pox_val_data[i]\n",
    "        val_pos_batch = mol_val_data[i]\n",
    "        \n",
    "        target_neg_scores = np.array([])\n",
    "\n",
    "        for j in range(len(mol_val_data)):\n",
    "            out, y = model(val_target_batch, \n",
    "                           val_pos_batch, \n",
    "                           decoy_batch=mol_val_data[j])\n",
    "\n",
    "            out = sigmoid(out)\n",
    "\n",
    "            if i == j:\n",
    "                target_pos_scores = out[torch.where(y==1)[0]].detach().cpu().numpy()\n",
    "            else:\n",
    "                negative_scores = out[torch.where(y==0)[0]].detach().cpu().numpy()\n",
    "                \n",
    "                if len(target_neg_scores) == 0:\n",
    "                    target_neg_scores = negative_scores\n",
    "                    \n",
    "                target_neg_scores = np.concatenate((target_neg_scores, \n",
    "                                                    negative_scores))\n",
    "                \n",
    "        # Combine the scores\n",
    "        scores = np.concatenate([target_pos_scores, target_neg_scores])\n",
    "        all_scores.append(scores)\n",
    "        total_mean_scores.append(np.mean(scores))\n",
    "\n",
    "        # Create labels: 1 for positive class, 0 for negative class\n",
    "        labels = np.concatenate([np.ones_like(target_pos_scores), \n",
    "                                 np.zeros_like(target_neg_scores)])\n",
    "\n",
    "        # Compute AUC\n",
    "        auc = roc_auc_score(labels, scores)\n",
    "        pos_mean = np.mean(target_pos_scores)\n",
    "        neg_mean = np.mean(target_neg_scores)\n",
    "        \n",
    "        total_auc_scores.append(auc)\n",
    "        total_pos_scores.append(pos_mean)\n",
    "        total_neg_scores.append(neg_mean)\n",
    "        \n",
    "        print(pos_mean, '--', neg_mean)\n",
    "        print(auc)\n",
    "        print('----------------------------------')\n",
    "    \n",
    "    return np.array(total_auc_scores), np.array(total_pos_scores), np.array(total_neg_scores), np.array(total_mean_scores), all_scores\n",
    "\n",
    "# a,p,n,m,s = validate(ac_model, pox_val_data, mol_val_data)\n",
    "# mean_a = np.mean(a)       \n",
    "\n",
    "# print(np.mean(a))\n",
    "# print(np.mean(p))\n",
    "# print(np.mean(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_class_freqs = torch.tensor(config['MOL_LABEL_COUNT'])\n",
    "vox_class_freqs = torch.tensor(config['POCKET_LABEL_COUNT'])\n",
    "\n",
    "mol_class_weights = 1./mol_class_freqs\n",
    "mol_class_weights = mol_class_weights * mol_class_freqs.sum() / len(mol_class_freqs)\n",
    "\n",
    "vox_class_weights = 1./vox_class_freqs\n",
    "vox_class_weights = vox_class_weights * vox_class_freqs.sum() / len(vox_class_freqs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------\n",
      "0.7470303773880005 0.4084528386592865 0.11995812505483627\n",
      "tensor([0.1113, 0.1417, 0.1284, 0.1583, 0.1516, 0.1108, 0.1054, 0.1140, 0.1110],\n",
      "       device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "-\n",
      "tensor([0.1113, 0.1417, 0.1284, 0.1583, 0.1516, 0.1108, 0.1054, 0.1140, 0.1110],\n",
      "       device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "-\n",
      "----\n",
      "tensor([0.9940, 0.0465, 0.0050, 0.2103, 0.0493, 0.2289, 0.1631, 0.1043, 0.0228],\n",
      "       device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "-\n",
      "tensor([3.2666e-04, 6.4137e-01, 9.3707e-01, 1.9382e-03, 1.5700e-02, 2.5839e-02,\n",
      "        1.4594e-02, 7.5217e-04, 7.4295e-03], device='cuda:0',\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "tensor([0., 0., 1., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "-\n",
      "----\n",
      "0.542 0.815 0.135 0.818 0.402 0.768 0.749 0.820 0.115 0.195 0.689 0.448 0.630 0.606 0.860 0.402\n",
      "tensor(0.5623, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "----\n",
      "0.417 0.702 0.818 0.001 0.045 0.024 0.001 0.286 0.773 0.705 0.624 0.429 0.656 0.862 0.029 0.651\n",
      "tensor(0.4389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "--------------------------------------------\n",
      "0.34989938139915466 0.48210036754608154 0.16522078216075897\n",
      "tensor([0.0996, 0.1465, 0.1352, 0.1629, 0.1551, 0.1145, 0.1133, 0.1124, 0.1153],\n",
      "       device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 1., 0., 0.], device='cuda:0')\n",
      "-\n",
      "tensor([0.0992, 0.1449, 0.1329, 0.1640, 0.1553, 0.1151, 0.1136, 0.1120, 0.1154],\n",
      "       device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "-\n",
      "----\n",
      "tensor([2.8821e-05, 2.3001e-03, 5.4800e-03, 3.3964e-01, 7.5956e-04, 1.0970e-01,\n",
      "        1.9694e-01, 1.9552e-04, 8.4416e-05], device='cuda:0',\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "-\n",
      "tensor([5.1543e-06, 8.8322e-04, 2.0057e-03, 5.1072e-01, 4.5953e-04, 1.6781e-01,\n",
      "        1.9284e-01, 1.2397e-03, 6.7765e-05], device='cuda:0',\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "-\n",
      "----\n",
      "0.765 0.696 0.907 0.689 0.690 0.814 0.425 0.573 0.685 0.934 0.715 0.602 0.766 0.685 0.867 0.743\n",
      "tensor(0.7222, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "----\n",
      "0.013 0.007 0.560 0.183 0.444 0.040 0.785 0.089 0.684 0.007 0.227 0.081 0.481 0.162 0.084 0.013\n",
      "tensor(0.2412, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 244.00 MiB (GPU 0; 15.89 GiB total capacity; 14.67 GiB already allocated; 168.12 MiB free; 14.94 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [31], line 76\u001b[0m\n\u001b[1;32m     73\u001b[0m vox_pred_y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mvstack((pox_batch\u001b[38;5;241m.\u001b[39my, decoy_pocket_batch\u001b[38;5;241m.\u001b[39my))[vox_interaction_indices]\n\u001b[1;32m     74\u001b[0m mol_pred_y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mvstack((mol_batch\u001b[38;5;241m.\u001b[39my, decoy_mol_batch\u001b[38;5;241m.\u001b[39my))[mol_interaction_indices]\n\u001b[0;32m---> 76\u001b[0m out, y, vox_preds, mol_preds \u001b[38;5;241m=\u001b[39m \u001b[43mac_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpox_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmol_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoy_pocket_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoy_mol_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m v_pred_loss \u001b[38;5;241m=\u001b[39m vox_prediction_loss(vox_preds[vox_interaction_indices], vox_pred_y)\n\u001b[1;32m     79\u001b[0m m_pred_loss \u001b[38;5;241m=\u001b[39m mol_prediction_loss(mol_preds[mol_interaction_indices], mol_pred_y)\n",
      "File \u001b[0;32m~/.conda/envs/vs-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/xdisk/twheeler/jgaiser/deepvs3/deepvs//models/active_classifier/ActiveClassifier.py:68\u001b[0m, in \u001b[0;36mActiveClassifier.forward\u001b[0;34m(self, pocket_batch, active_batch, decoy_pockets, decoy_batch)\u001b[0m\n\u001b[1;32m     66\u001b[0m     decoy_pockets \u001b[38;5;241m=\u001b[39m deepcopy(decoy_pockets)\n\u001b[1;32m     67\u001b[0m     decoy_pockets\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m decoy_voxel_embeds\n\u001b[0;32m---> 68\u001b[0m     decoy_poxel_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpox_agg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoy_pockets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoy_voxel_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m     vox_interaction_preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mvstack((vox_interaction_preds, \n\u001b[1;32m     71\u001b[0m                                           decoy_vox_interaction_preds))  \n\u001b[1;32m     73\u001b[0m active_atom_embeds, mol_preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmol_embedder(active_batch)\n",
      "File \u001b[0;32m~/.conda/envs/vs-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/xdisk/twheeler/jgaiser/deepvs3/deepvs//models/poxel_aggregator/PoxelGCN.py:120\u001b[0m, in \u001b[0;36mPoxelGCN.forward\u001b[0;34m(self, data, voxel_indices)\u001b[0m\n\u001b[1;32m    117\u001b[0m edge_weights \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnorm(pos[edge_index[\u001b[38;5;241m0\u001b[39m]] \u001b[38;5;241m-\u001b[39m pos[edge_index[\u001b[38;5;241m1\u001b[39m]], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    118\u001b[0m edge_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medge_MLP2(edge_weights)\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[0;32m--> 120\u001b[0m h1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(h \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv4\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weights\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    121\u001b[0m h1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm4(h1)\n\u001b[1;32m    123\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(h \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv5(h1, edge_index, edge_weights))\n",
      "File \u001b[0;32m~/.conda/envs/vs-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/vs-env/lib/python3.10/site-packages/torch_geometric/nn/conv/gatv2_conv.py:236\u001b[0m, in \u001b[0;36mGATv2Conv.forward\u001b[0;34m(self, x, edge_index, edge_attr, return_attention_weights)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    231\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe usage of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_attr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madd_self_loops\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    232\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimultaneously is currently not yet supported for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    233\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_index\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m in a \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSparseTensor\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m form\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    235\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: PairTensor, edge_attr: OptTensor)\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_l\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_r\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m                     \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_alpha\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/vs-env/lib/python3.10/site-packages/torch_geometric/nn/conv/message_passing.py:374\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    373\u001b[0m         msg_kwargs \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(res, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m res\n\u001b[0;32m--> 374\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmsg_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_message_forward_hooks\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m    376\u001b[0m     res \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, (msg_kwargs, ), out)\n",
      "File \u001b[0;32m~/.conda/envs/vs-env/lib/python3.10/site-packages/torch_geometric/nn/conv/gatv2_conv.py:273\u001b[0m, in \u001b[0;36mGATv2Conv.message\u001b[0;34m(self, x_j, x_i, edge_attr, index, ptr, size_i)\u001b[0m\n\u001b[1;32m    270\u001b[0m     x \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m edge_attr\n\u001b[1;32m    272\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mleaky_relu(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnegative_slope)\n\u001b[0;32m--> 273\u001b[0m alpha \u001b[38;5;241m=\u001b[39m (\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43matt\u001b[49m)\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    274\u001b[0m alpha \u001b[38;5;241m=\u001b[39m softmax(alpha, index, ptr, size_i)\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_alpha \u001b[38;5;241m=\u001b[39m alpha\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 244.00 MiB (GPU 0; 15.89 GiB total capacity; 14.67 GiB already allocated; 168.12 MiB free; 14.94 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# # torch.manual_seed(1234)\n",
    "# with open(config_path, \"r\") as config_file:\n",
    "#     config = yaml.safe_load(config_file)\n",
    "\n",
    "# VoxEmbedder = load_class_from_file(config['vox_embedder_model'] % root_path)\n",
    "# PoxelAggregator = load_class_from_file(config['poxel_aggregator_model'] % root_path)\n",
    "# MolEmbedder = load_class_from_file(config['mol_embedder_model'] % root_path)\n",
    "# MolAggregator = load_class_from_file(config['mol_aggregator_model'] % root_path)\n",
    "\n",
    "# config['active_classifier_hyperparams']['in_dim'] = config['mol_aggregator_hyperparams']['out_dim'] + config['poxel_aggregator_hyperparams']['out_dim'] \n",
    "    \n",
    "# ActiveClassifier = load_class_from_file(config['active_classifier_model'] % root_path)\n",
    "\n",
    "# ac_model = ActiveClassifier(\n",
    "#     voxel_embedder=(VoxEmbedder, config['vox_embedder_hyperparams']),\n",
    "#     poxel_model=(PoxelAggregator, config['poxel_aggregator_hyperparams']),\n",
    "#     mol_embed_model=(MolEmbedder, config['mol_embedder_hyperparams']),  \n",
    "#     mol_agg_model = (MolAggregator, config['mol_aggregator_hyperparams']),\n",
    "#     **config['active_classifier_hyperparams']).to(device)\n",
    "\n",
    "# # Define the learning rates for each module\n",
    "# learning_rates = {\n",
    "#     'vox_embedder': 1e-3,\n",
    "#     'pox_agg': 1e-5,\n",
    "#     'mol_embedder': 1e-3,\n",
    "#     'mol_agg': 1e-4,\n",
    "#     'ac_model': 1e-4,\n",
    "# }\n",
    "\n",
    "# # Create separate optimizers for each module with their respective learning rates\n",
    "# optimizers = {\n",
    "#     'vox_embedder': torch.optim.Adam(ac_model.vox_embedder.parameters(), lr=learning_rates['vox_embedder']),\n",
    "#     'pox_agg': torch.optim.Adam(ac_model.pox_agg.parameters(), lr=learning_rates['pox_agg']),\n",
    "#     'mol_embedder': torch.optim.Adam(ac_model.mol_embedder.parameters(), lr=learning_rates['mol_embedder']),\n",
    "#     'mol_agg': torch.optim.Adam(ac_model.mol_agg.parameters(), lr=learning_rates['mol_agg']),\n",
    "#     'ac_model': torch.optim.Adam(ac_model.parameters(), lr=learning_rates['ac_model'])\n",
    "# }\n",
    "\n",
    "\n",
    "\n",
    "# BATCH_SIZE = 16  \n",
    "# # optimizer = torch.optim.AdamW(ac_model.parameters(), lr=1e-5)\n",
    "# optimizer = torch.optim.Adam(ac_model.parameters(), lr=1e-4)\n",
    "\n",
    "# vox_prediction_loss = nn.BCEWithLogitsLoss(pos_weight=vox_class_weights).to(device) \n",
    "# mol_prediction_loss = nn.BCEWithLogitsLoss(pos_weight=mol_class_weights).to(device) \n",
    "# ac_loss = nn.BCEWithLogitsLoss().to(device) \n",
    "    \n",
    "# ac_model.train()\n",
    "# # ac_model.eval()\n",
    "# best_a = 0.8\n",
    "\n",
    "for epoch in range(1, 100):\n",
    "    for batch_index in range(int(len(pox_train_set) / BATCH_SIZE)):  \n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        pox_batch, mol_batch = get_random_batch_pair(pox_train_set, mol_train_set, device, batch_size=BATCH_SIZE, min_prob=0.1)\n",
    "        decoy_pocket_batch, _ = get_random_batch_pair(pox_train_set, mol_train_set, device, batch_size=BATCH_SIZE, min_prob=0.1)\n",
    "        _, decoy_mol_batch = get_random_batch_pair(pox_train_set, mol_train_set, device, batch_size=BATCH_SIZE, min_prob=0.1)\n",
    "        \n",
    "        vox_interaction_indices = torch.nonzero(pox_batch.y)[:,0]\n",
    "        decoy_vox_interaction_indices = torch.nonzero(decoy_pocket_batch.y)[:,0]\n",
    "        \n",
    "        mol_interaction_indices = torch.nonzero(mol_batch.y)[:,0]\n",
    "        decoy_mol_interaction_indices = torch.nonzero(decoy_mol_batch.y)[:,0]\n",
    "        \n",
    "        vox_interaction_indices = (torch.hstack((vox_interaction_indices, \n",
    "                                                len(pox_batch.y) + decoy_vox_interaction_indices)))\n",
    "        \n",
    "        mol_interaction_indices = (torch.hstack((mol_interaction_indices, \n",
    "                                                len(mol_batch.y) + decoy_mol_interaction_indices)))\n",
    "        \n",
    "        vox_pred_y = torch.vstack((pox_batch.y, decoy_pocket_batch.y))[vox_interaction_indices]\n",
    "        mol_pred_y = torch.vstack((mol_batch.y, decoy_mol_batch.y))[mol_interaction_indices]\n",
    "        \n",
    "        out, y, vox_preds, mol_preds = ac_model(pox_batch, mol_batch, decoy_pocket_batch, decoy_mol_batch)\n",
    "    \n",
    "        v_pred_loss = vox_prediction_loss(vox_preds[vox_interaction_indices], vox_pred_y)\n",
    "        m_pred_loss = mol_prediction_loss(mol_preds[mol_interaction_indices], mol_pred_y)\n",
    "        \n",
    "        pos_indices = torch.where(y==1)[0]\n",
    "        neg_indices = torch.where(y==0)[0]\n",
    "            \n",
    "        l1 = ac_loss(out, y.unsqueeze(1).to(device))\n",
    "        l = l1 + 0.5*v_pred_loss + 0.1*m_pred_loss\n",
    "        \n",
    "        for k,o in optimizers.items():\n",
    "            o.zero_grad()\n",
    "            \n",
    "        l.backward()\n",
    "        \n",
    "        for k,o in optimizers.items():\n",
    "            o.step()\n",
    "        \n",
    "        if batch_index % 100 == 0:\n",
    "            print('--------------------------------------------')\n",
    "            print(l1.item(), v_pred_loss.item(), m_pred_loss.item())\n",
    "            \n",
    "            random_interaction_indices = torch.randperm(len(vox_interaction_indices))[:2]\n",
    "            for i in random_interaction_indices:\n",
    "                print(sigmoid(vox_preds[vox_interaction_indices][i]))\n",
    "                print(vox_pred_y[i])\n",
    "                print('-')\n",
    "                \n",
    "            print('----')\n",
    "            \n",
    "            random_interaction_indices = torch.randperm(len(mol_interaction_indices))[:2]\n",
    "            for i in random_interaction_indices:\n",
    "                print(sigmoid(mol_preds[mol_interaction_indices][i]))\n",
    "                print(mol_pred_y[i])\n",
    "                print('-')    \n",
    "                \n",
    "            print('----')\n",
    "            print(\" \".join([\"%.3f\" % x for x in sigmoid(out[pos_indices].flatten())]))\n",
    "            print(torch.mean(sigmoid(out[pos_indices].flatten())))\n",
    "            print('----')\n",
    "            print(\" \".join([\"%.3f\" % x for x in sigmoid(out[neg_indices].flatten())]))\n",
    "            print(torch.mean(sigmoid(out[neg_indices].flatten())))\n",
    "            \n",
    "    print(\"EPOCH %s COMPLETE\" % (epoch))\n",
    "    \n",
    "#     if (epoch+1) % 5 == 0:\n",
    "#         ac_model.eval()\n",
    "\n",
    "    if epoch < 10:\n",
    "        continue\n",
    "        \n",
    "    if epoch % 3 == 0:\n",
    "        a,p,n,_,_ = validate(ac_model, pox_val_data, mol_val_data)\n",
    "        mean_a = np.mean(a)       \n",
    "        \n",
    "        print(np.mean(a))\n",
    "        print(np.mean(p))\n",
    "        print(np.mean(n))\n",
    "        \n",
    "        if mean_a > best_a:\n",
    "            torch.save(ac_model.state_dict(), ac_weights)\n",
    "            print('WEIGHTS UPDATED')\n",
    "            best_a = mean_a\n",
    "            \n",
    "        ac_model.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vs-env",
   "language": "python",
   "name": "vs-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
