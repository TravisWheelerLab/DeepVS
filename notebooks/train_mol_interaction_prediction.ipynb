{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from glob import glob\n",
    "import torch\n",
    "import torch_geometric\n",
    "import random\n",
    "import yaml\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils import remove_isolated_nodes\n",
    "from torch import nn\n",
    "from torch_geometric.nn import GCN2Conv\n",
    "from torch_geometric.nn import SAGPooling\n",
    "from torch_geometric.nn import MLP\n",
    "from torch_geometric.nn import AttentiveFP\n",
    "from torch_geometric.nn.aggr import AttentionalAggregation\n",
    "from copy import deepcopy \n",
    "from torch_geometric.nn import GATConv, MessagePassing, global_add_pool\n",
    "from torch.nn import TripletMarginLoss\n",
    "import importlib\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# holdout_complexes = [\"3gdt\", \"3g1v\", \"3w07\", \"3g1d\", \"1loq\", \"3wjw\", \"2zz1\", \"2zz2\", \"1km3\", \"1x1z\", \n",
    "#                      \"6cbg\", \"5j7q\", \"6cbf\", \"4wrb\", \"6b1k\", \"5hvs\", \"5hvt\", \"3rf5\", \"3rf4\", \"1mfi\", \n",
    "#                      \"5efh\", \"6csq\", \"5efj\", \"6csr\", \"6css\", \"6csp\", \"5een\", \"5ef7\", \"5eek\", \"5eei\",\n",
    "#                      \"3ozt\", \"3u81\", \"4p58\", \"5k03\", \"3ozr\", \"3ozs\", \"3oe5\", \"3oe4\", \"3hvi\", \"3hvj\",\n",
    "#                      \"3g2y\", \"3g2z\", \"3g30\", \"3g31\", \"3g34\", \"3g32\", \"4de2\", \"3g35\", \"4de0\", \"4de1\",\n",
    "#                      \"2exm\", \"4i3z\", \"1e1v\", \"5jq5\", \"1jsv\", \"1e1x\", \"4bcp\", \"4eor\", \"1b38\", \"1pxp\", \"2xnb\", \"4bco\", \"4bcm\", \"1pxn\", \"4bcn\", \"1h1s\", \"4bck\", \"2fvd\", \"1pxo\", \"2xmy\",\n",
    "#                      \"4xoe\", \"5fs5\", \"1uwf\", \"4att\", \"4av4\", \"4av5\", \"4avh\", \"4avj\", \"4avi\", \"4auj\", \"4x50\", \"4lov\", \"4x5r\", \"4buq\", \"4x5p\", \"4css\", \"4xoc\", \"4cst\", \"4xo8\", \"4x5q\",\n",
    "#                      \"1gpk\", \"3zv7\", \"1gpn\", \"5bwc\", \"5nau\", \"5nap\", \"1h23\", \"1h22\", \"1e66\", \"4m0e\", \"4m0f\", \"2ha3\", \"2whp\", \"2ha6\", \"2ha2\", \"1n5r\", \"4arb\", \"4ara\", \"5ehq\", \"1q84\",\n",
    "#                      \"2z1w\", \"3rr4\", \"1s38\", \"1q65\", \"4q4q\", \"4q4p\", \"4q4r\", \"4kwo\", \"1r5y\", \"4leq\", \"4lbu\", \"1f3e\", \"4pum\", \"4q4s\", \"3gc5\", \"2qzr\", \"4q4o\", \"3gc4\", \"5jxq\", \"3ge7\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = '/xdisk/twheeler/jgaiser/deepvs3/deepvs/'\n",
    "params_path = root_path + 'params.yaml'\n",
    "config_path = root_path + 'config.yaml'\n",
    "\n",
    "def load_class_from_file(file_path):\n",
    "    class_name = file_path.split(\"/\")[-1].split(\".\")[0]\n",
    "    spec = importlib.util.spec_from_file_location(class_name, file_path)\n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(module)\n",
    "    return getattr(module, class_name)\n",
    "\n",
    "\n",
    "def load_function_from_file(file_path):\n",
    "    function_name = file_path.split(\"/\")[-1].split(\".\")[0]\n",
    "    spec = importlib.util.spec_from_file_location(\n",
    "        os.path.basename(file_path), file_path\n",
    "    )\n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "    sys.modules[spec.name] = module\n",
    "    spec.loader.exec_module(module)\n",
    "    return getattr(module, function_name) \n",
    "\n",
    "\n",
    "with open(params_path, \"r\") as param_file:\n",
    "    params = yaml.safe_load(param_file)\n",
    "    \n",
    "with open(config_path, \"r\") as config_file:\n",
    "    config = yaml.safe_load(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATOM_LABELS = config['POCKET_ATOM_LABELS']\n",
    "MOL_ATOM_LABELS = config['MOL_ATOM_LABELS']\n",
    "EDGE_LABELS = config['POCKET_EDGE_LABELS']\n",
    "INTERACTION_LABELS = config['INTERACTION_LABELS']\n",
    "\n",
    "mol_graph_ft = params['data_dir'] + config['mol_graph_file_template']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_class_freqs = torch.tensor(config['MOL_LABEL_COUNT'])\n",
    "\n",
    "mol_class_weights = 1./mol_class_freqs\n",
    "mol_class_weights = mol_class_weights * mol_class_freqs.sum() / len(mol_class_freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_sample_files = glob(mol_graph_ft.replace('%s', '*'))\n",
    "mol_training_data = []\n",
    "\n",
    "for graph_file in training_sample_files:\n",
    "    mol_training_data.append(pickle.load(open(graph_file, 'rb')))\n",
    "    \n",
    "random.shuffle(mol_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(mol_training_data[0].y,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_class_N = 40 \n",
    "\n",
    "val_set = []\n",
    "train_set = []\n",
    "\n",
    "val_class_counts = torch.zeros(len(INTERACTION_LABELS))\n",
    "\n",
    "for g_i, mol_g in enumerate(mol_training_data):\n",
    "    if torch.sum(mol_g.y) == 0:\n",
    "        continue\n",
    "        \n",
    "    is_val = False\n",
    "    y_totals = torch.sum(mol_g.y, dim=0)\n",
    "    \n",
    "    for i_index in torch.where(y_totals >0)[0]:\n",
    "        if val_class_counts[i_index] < val_class_N:\n",
    "            val_set.append(mol_g)\n",
    "            val_class_counts += y_totals\n",
    "            is_val = True\n",
    "            break\n",
    "            \n",
    "    if is_val:\n",
    "        continue\n",
    "    \n",
    "    train_set.append(mol_g)\n",
    "\n",
    "def batch_logit_accuracy(logits_batch, labels_batch):\n",
    "    batch_size = logits_batch.size(0)\n",
    "    accuracies = torch.zeros(batch_size)\n",
    "\n",
    "    i=0\n",
    "    for logits,labels in zip(logits_batch, labels_batch):\n",
    "\n",
    "        num_ones = torch.sum(labels).item()\n",
    "        topk_values, topk_indices = torch.topk(logits, int(num_ones))\n",
    "\n",
    "        label_indices = (labels == 1).nonzero(as_tuple=True)[0]\n",
    "    \n",
    "        correct = torch.eq(topk_indices.sort()[0], label_indices.sort()[0]).sum().item()\n",
    "\n",
    "        accuracies[i] = correct / num_ones\n",
    "        i+=1\n",
    "\n",
    "    return torch.mean(accuracies).item()\n",
    "\n",
    "BATCH_SIZE = 32 \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_loader = DataLoader(train_set, shuffle=True, batch_size=BATCH_SIZE) \n",
    "validation_batch = next(iter(DataLoader(val_set, shuffle=False, batch_size=len(val_set)))).to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/xdisk/twheeler/jgaiser/deepvs3/deepvs/models/weights/mol_embedder_6-1.m'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_path[:-1] + config['mol_embedder_weights']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss(pos_weight=mol_class_weights).to(device)\n",
    "val_criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "\n",
    "MolEmbedder = load_class_from_file(root_path+config['mol_embedder_model'])\n",
    "mol_model = MolEmbedder(**config['mol_embedder_hyperparams']).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(mol_model.parameters(), lr=1e-3)\n",
    "sigmoid = nn.Sigmoid()\n",
    "\n",
    "validation_loss_history = []\n",
    "validation_accuracy_history = []\n",
    "\n",
    "training_loss_history = []\n",
    "training_accuracy_history = []\n",
    "\n",
    "for epoch in range(100):\n",
    "    print(\"EPOCH %s\" % epoch)\n",
    "    loss_history = None\n",
    "    \n",
    "    for batch_index, batch in enumerate(train_loader):\n",
    "        batch = batch.to(device)\n",
    "        interacting_atoms = torch.where(torch.sum(batch.y, dim=1) > 0)[0] \n",
    "        y = batch.y[interacting_atoms]\n",
    "       \n",
    "        _, interaction_preds, mol_embed = mol_model(batch)\n",
    "        interaction_preds = interaction_preds[interacting_atoms]\n",
    "        \n",
    "        loss = criterion(interaction_preds, y.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if loss_history is None:\n",
    "            loss_history = loss\n",
    "        else:\n",
    "            loss_history = torch.vstack((loss_history, loss))\n",
    "            \n",
    "        if batch_index % 1000 == 0:\n",
    "            training_loss_history.append(torch.mean(loss_history).item())\n",
    "            print(\"Loss: %s\" % torch.mean(loss_history).item())\n",
    "            print(\"Accuracy: %s\" % batch_logit_accuracy(interaction_preds, y))\n",
    "\n",
    "            for i in torch.randperm(len(y))[:3]:\n",
    "                print(\"%.2f \"*len(INTERACTION_LABELS) % tuple(sigmoid(interaction_preds[i]).tolist()))\n",
    "                print(\"%.2f \"*len(INTERACTION_LABELS) % tuple(y[i].tolist()))\n",
    "                print(\"\")\n",
    "\n",
    "            loss_history = None \n",
    "    \n",
    "    mol_model.eval()\n",
    "    with torch.no_grad():\n",
    "        _, validation_preds, _ = mol_model(validation_batch)\n",
    "        \n",
    "        val_interacting_atoms = torch.where(torch.sum(validation_batch.y, dim=1) > 0)[0] \n",
    "        validation_y = validation_batch.y[val_interacting_atoms]\n",
    "        validation_preds = validation_preds[val_interacting_atoms]\n",
    "        \n",
    "        validation_loss = val_criterion(validation_preds, validation_y.float()).item()\n",
    "        validation_accuracy = batch_logit_accuracy(validation_preds, validation_y)\n",
    "        \n",
    "        if len(validation_loss_history) > 0: \n",
    "            if validation_accuracy > max(validation_accuracy_history):\n",
    "                torch.save(mol_model.state_dict(), root_path[:-1] + config['mol_embedder_weights'])\n",
    "                print('WEIGHTS UPDATED')\n",
    "        \n",
    "        validation_loss_history.append(validation_loss)\n",
    "        validation_accuracy_history.append(validation_accuracy)\n",
    "        \n",
    "        print(\"VALIDATION LOSS:\", validation_loss)\n",
    "        print(\"VALIDATION ACC:\", validation_accuracy)\n",
    "    mol_model.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vs-env",
   "language": "python",
   "name": "vs-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
