{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from glob import glob\n",
    "import torch\n",
    "import torch_geometric\n",
    "import random\n",
    "import yaml\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils import remove_isolated_nodes\n",
    "from torch import nn\n",
    "from torch_geometric.nn import GCN2Conv\n",
    "from torch_geometric.nn import SAGPooling\n",
    "from torch_geometric.nn import MLP\n",
    "from torch_geometric.nn import AttentiveFP\n",
    "from torch_geometric.nn.aggr import AttentionalAggregation\n",
    "from copy import deepcopy \n",
    "from torch_geometric.nn import GATConv, MessagePassing, global_add_pool\n",
    "from torch.nn import TripletMarginLoss\n",
    "import importlib\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_complexes = [\"3gdt\", \"3g1v\", \"3w07\", \"3g1d\", \"1loq\", \"3wjw\", \"2zz1\", \"2zz2\", \"1km3\", \"1x1z\", \n",
    "                     \"6cbg\", \"5j7q\", \"6cbf\", \"4wrb\", \"6b1k\", \"5hvs\", \"5hvt\", \"3rf5\", \"3rf4\", \"1mfi\", \n",
    "                     \"5efh\", \"6csq\", \"5efj\", \"6csr\", \"6css\", \"6csp\", \"5een\", \"5ef7\", \"5eek\", \"5eei\",\n",
    "                     \"3ozt\", \"3u81\", \"4p58\", \"5k03\", \"3ozr\", \"3ozs\", \"3oe5\", \"3oe4\", \"3hvi\", \"3hvj\",\n",
    "                     \"3g2y\", \"3g2z\", \"3g30\", \"3g31\", \"3g34\", \"3g32\", \"4de2\", \"3g35\", \"4de0\", \"4de1\",\n",
    "                     \"2exm\", \"4i3z\", \"1e1v\", \"5jq5\", \"1jsv\", \"1e1x\", \"4bcp\", \"4eor\", \"1b38\", \"1pxp\", \"2xnb\", \"4bco\", \"4bcm\", \"1pxn\", \"4bcn\", \"1h1s\", \"4bck\", \"2fvd\", \"1pxo\", \"2xmy\",\n",
    "                     \"4xoe\", \"5fs5\", \"1uwf\", \"4att\", \"4av4\", \"4av5\", \"4avh\", \"4avj\", \"4avi\", \"4auj\", \"4x50\", \"4lov\", \"4x5r\", \"4buq\", \"4x5p\", \"4css\", \"4xoc\", \"4cst\", \"4xo8\", \"4x5q\",\n",
    "                     \"1gpk\", \"3zv7\", \"1gpn\", \"5bwc\", \"5nau\", \"5nap\", \"1h23\", \"1h22\", \"1e66\", \"4m0e\", \"4m0f\", \"2ha3\", \"2whp\", \"2ha6\", \"2ha2\", \"1n5r\", \"4arb\", \"4ara\", \"5ehq\", \"1q84\",\n",
    "                     \"2z1w\", \"3rr4\", \"1s38\", \"1q65\", \"4q4q\", \"4q4p\", \"4q4r\", \"4kwo\", \"1r5y\", \"4leq\", \"4lbu\", \"1f3e\", \"4pum\", \"4q4s\", \"3gc5\", \"2qzr\", \"4q4o\", \"3gc4\", \"5jxq\", \"3ge7\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_path = '/xdisk/twheeler/jgaiser/deepvs3/deepvs_params.yaml'\n",
    "config_path = '/xdisk/twheeler/jgaiser/deepvs3/deepvs/config.yaml'\n",
    "root_path = '/xdisk/twheeler/jgaiser/deepvs3/deepvs/'\n",
    "function_path = root_path + 'code/utils/data_processing_utils.py'\n",
    "\n",
    "def load_class_from_file(file_path):\n",
    "    class_name = file_path.split(\"/\")[-1].split(\".\")[0]\n",
    "    spec = importlib.util.spec_from_file_location(class_name, file_path)\n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(module)\n",
    "    return getattr(module, class_name)\n",
    "\n",
    "\n",
    "def load_function_from_file(file_path):\n",
    "    function_name = file_path.split(\"/\")[-1].split(\".\")[0]\n",
    "    spec = importlib.util.spec_from_file_location(\n",
    "        os.path.basename(file_path), file_path\n",
    "    )\n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "    sys.modules[spec.name] = module\n",
    "    spec.loader.exec_module(module)\n",
    "    return getattr(module, function_name) \n",
    "\n",
    "\n",
    "with open(params_path, \"r\") as param_file:\n",
    "    params = yaml.safe_load(param_file)\n",
    "    \n",
    "with open(config_path, \"r\") as config_file:\n",
    "    config = yaml.safe_load(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATOM_LABELS = config['POCKET_ATOM_LABELS']\n",
    "MOL_ATOM_LABELS = config['MOL_ATOM_LABELS']\n",
    "EDGE_LABELS = config['POCKET_EDGE_LABELS']\n",
    "INTERACTION_LABELS = config['INTERACTION_LABELS']\n",
    "\n",
    "mol_graph_ft = params['data_dir'] + config['mol_graph_file_template']\n",
    "training_sample_ft = params['data_dir'] + config['training_sample_file_template']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pocket_class_freqs = torch.tensor(config['POCKET_LABEL_COUNT'])\n",
    "mol_class_freqs = torch.tensor(config['MOL_LABEL_COUNT'])\n",
    "\n",
    "pocket_class_weights = 1./pocket_class_freqs\n",
    "pocket_class_weights = pocket_class_weights * pocket_class_freqs.sum() / len(pocket_class_freqs)\n",
    "\n",
    "mol_class_weights = 1./mol_class_freqs\n",
    "mol_class_weights = mol_class_weights * mol_class_freqs.sum() / len(mol_class_freqs)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pdb_ids = []\n",
    "\n",
    "training_sample_dict = {}\n",
    "training_sample_files = glob(training_sample_ft.replace('%s', '*'))\n",
    "\n",
    "for graph_col_file in training_sample_files:\n",
    "    pdb_id = graph_col_file.split('/')[-1].split('_')[0]\n",
    "    \n",
    "    if pdb_id not in holdout_complexes:\n",
    "        pdb_ids.append(pdb_id)\n",
    "    \n",
    "    training_sample_dict[pdb_id] = pickle.load(open(graph_col_file, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mol_dict = {}\n",
    "mol_graph_files = glob(mol_graph_ft.replace('%s','*'))\n",
    "\n",
    "for graph_file in mol_graph_files:\n",
    "    pdb_id = graph_file.split('/')[-1].split('_')[0]\n",
    "    g = pickle.load(open(graph_file, 'rb'))\n",
    "    g.pdb_id = pdb_id\n",
    "    mol_dict[pdb_id] = g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vox_batch(vox_dict, id_list):\n",
    "    batch_a = []\n",
    "    batch_b = []\n",
    "    \n",
    "    for pdb_id in id_list:\n",
    "        sample_a, sample_b = random.choices(vox_dict[pdb_id], k=2)\n",
    "        batch_a.append(sample_a)\n",
    "        batch_b.append(sample_b)\n",
    "        \n",
    "    return (next(iter(DataLoader(batch_a, \n",
    "                                shuffle=False, \n",
    "                                batch_size=len(id_list)))), \n",
    "            \n",
    "            next(iter(DataLoader(batch_b,                                   \n",
    "                                 shuffle=False,\n",
    "                                 batch_size=len(id_list)))))\n",
    "\n",
    "\n",
    "def get_mol_batch(mol_collection, pdb_ids):\n",
    "    return next(iter(DataLoader([mol_collection[x] for x in pdb_ids], \n",
    "                                shuffle=False, \n",
    "                                batch_size = len(pdb_ids))))    \n",
    "\n",
    "\n",
    "def get_batch_indices(vox_batch, mol_batch):\n",
    "    vox_interaction_indices = torch.where(torch.sum(vox_batch.y, dim=1) != 0)[0]\n",
    "    vox_contact_indices = torch.where(vox_batch.contact_map != -1)[0]\n",
    "    \n",
    "    mol_interaction_indices = torch.where(torch.sum(mol_batch.y, dim=1) != 0)[0]\n",
    "    mol_contact_indices = mol_batch.ptr[vox_contact_indices] + vox_batch.contact_map[vox_contact_indices]\n",
    "    \n",
    "    return (vox_interaction_indices, \n",
    "            vox_contact_indices, \n",
    "            mol_interaction_indices, \n",
    "            mol_contact_indices)\n",
    "\n",
    "\n",
    "def get_shuffled_mol_indices(mol_batch):\n",
    "    shuffled_indices = []\n",
    "    \n",
    "    for ptr_i in range(1, mol_batch.ptr.size(0)):\n",
    "        mol_start = mol_batch.ptr[ptr_i-1]\n",
    "        mol_stop = mol_batch.ptr[ptr_i]\n",
    "        \n",
    "        mol_indices = torch.arange(mol_start, mol_stop)\n",
    "        heavy_indices = mol_indices[mol_batch.heavy[mol_indices]==1]\n",
    "        heavy_indices = heavy_indices[torch.randperm(heavy_indices.size(0))]\n",
    "        light_indices = mol_indices[mol_batch.heavy[mol_indices]==0]\n",
    "        \n",
    "        shuffled_indices.extend([heavy_indices, light_indices])\n",
    "    \n",
    "    return torch.hstack(shuffled_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64 \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "criterion1 = nn.BCEWithLogitsLoss(pos_weight=pocket_class_weights).to(device)\n",
    "criterion2 = nn.BCEWithLogitsLoss(pos_weight=mol_class_weights).to(device)\n",
    "\n",
    "criterion3 = TripletMarginLoss(margin=0.5, p=2).to(device)\n",
    "criterion4 = TripletMarginLoss(margin=0.5, p=2).to(device)\n",
    "\n",
    "VoxEncoder = load_class_from_file(params['vox_encoder_model'])\n",
    "vox_data_transform = load_function_from_file(params['vox_encoder_data_transform'])\n",
    "params['vox_encoder_hyperparams']['data_transform'] = vox_data_transform\n",
    "voxel_model = VoxEncoder(**params['vox_encoder_hyperparams']).to(device)\n",
    "\n",
    "MolEncoder = load_class_from_file(params['mol_encoder_model'])\n",
    "params['mol_encoder_hyperparams']['data_transform'] = None\n",
    "mol_model = MolEncoder(**params['mol_encoder_hyperparams']).to(device)\n",
    "\n",
    "v_optimizer = torch.optim.Adam(voxel_model.parameters(), lr=1e-3)\n",
    "m_optimizer = torch.optim.Adam(mol_model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "582505"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOX_COUNT = 0\n",
    "for k,v in training_sample_dict.items():\n",
    "     VOX_COUNT += len(v)\n",
    "VOX_COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0\n",
      "tensor([0.7429, 0.7346, 0.4932, 0.5037], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7234, 0.6970, 0.5008, 0.4993], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7213, 0.6984, 0.5000, 0.5019], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7251, 0.7101, 0.5002, 0.4994], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7269, 0.7115, 0.4994, 0.4987], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7294, 0.7149, 0.5001, 0.4977], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7281, 0.7140, 0.4998, 0.4995], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7284, 0.7145, 0.4999, 0.4986], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7277, 0.7143, 0.4997, 0.4965], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7274, 0.7145, 0.4995, 0.4976], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "EPOCH 1\n",
      "tensor([0.7103, 0.6994, 0.4705, 0.4488], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7263, 0.7133, 0.5001, 0.4977], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7266, 0.7130, 0.4994, 0.5030], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7299, 0.7131, 0.4994, 0.5021], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7264, 0.7141, 0.5000, 0.4990], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7277, 0.7129, 0.5003, 0.4953], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7294, 0.7134, 0.4997, 0.5000], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7270, 0.7129, 0.4997, 0.5035], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7271, 0.7123, 0.5000, 0.5001], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7278, 0.7128, 0.5001, 0.5019], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "EPOCH 2\n",
      "tensor([0.7133, 0.7299, 0.5006, 0.6366], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7251, 0.7120, 0.4999, 0.5000], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7277, 0.7131, 0.4992, 0.5027], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7295, 0.7136, 0.4998, 0.5013], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7295, 0.7134, 0.5002, 0.5000], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7307, 0.7137, 0.5001, 0.4994], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7271, 0.7137, 0.4997, 0.4999], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7321, 0.7141, 0.4994, 0.4982], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7320, 0.7147, 0.4999, 0.5004], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7281, 0.7131, 0.4996, 0.5009], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "EPOCH 3\n",
      "tensor([0.7734, 0.7198, 0.4964, 0.5037], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7300, 0.7139, 0.4998, 0.5004], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7279, 0.7145, 0.5000, 0.5015], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7297, 0.7139, 0.5000, 0.4999], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7290, 0.7143, 0.4999, 0.5017], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7288, 0.7151, 0.4990, 0.4987], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7319, 0.7147, 0.4996, 0.4997], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7261, 0.7142, 0.4998, 0.4976], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7287, 0.7145, 0.4995, 0.5003], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7281, 0.7142, 0.5008, 0.4965], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "EPOCH 4\n",
      "tensor([0.7515, 0.7299, 0.5007, 0.5870], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7300, 0.7144, 0.5001, 0.4985], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7291, 0.7147, 0.4993, 0.4988], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7288, 0.7145, 0.5004, 0.5025], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7282, 0.7143, 0.5006, 0.5028], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7288, 0.7142, 0.5003, 0.5051], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7276, 0.7135, 0.5001, 0.5025], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7295, 0.7141, 0.5001, 0.5008], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7282, 0.7138, 0.4999, 0.4992], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7292, 0.7144, 0.5003, 0.4994], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "EPOCH 5\n",
      "tensor([0.7018, 0.7508, 0.5096, 0.5971], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7299, 0.7139, 0.5005, 0.4993], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7303, 0.7136, 0.5001, 0.4997], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7289, 0.7139, 0.5001, 0.5027], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7296, 0.7143, 0.4985, 0.4979], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7295, 0.7144, 0.4997, 0.4998], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7289, 0.7145, 0.4997, 0.4996], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7294, 0.7153, 0.5000, 0.4997], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7300, 0.7151, 0.4997, 0.5023], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7294, 0.7143, 0.5000, 0.5029], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "EPOCH 6\n",
      "tensor([0.7332, 0.7152, 0.4753, 0.5394], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7329, 0.7148, 0.4990, 0.4992], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7295, 0.7140, 0.4999, 0.4986], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7323, 0.7150, 0.4992, 0.5015], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7286, 0.7137, 0.5000, 0.5034], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7288, 0.7147, 0.5006, 0.5051], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7291, 0.7143, 0.4994, 0.5000], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7297, 0.7145, 0.4999, 0.5019], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7315, 0.7145, 0.4996, 0.5002], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7328, 0.7139, 0.4997, 0.4996], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "EPOCH 7\n",
      "tensor([0.7173, 0.7599, 0.5114, 0.5623], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7310, 0.7142, 0.5006, 0.4977], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7307, 0.7135, 0.4995, 0.4989], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7310, 0.7142, 0.5003, 0.5009], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7316, 0.7146, 0.4998, 0.5012], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7308, 0.7143, 0.4995, 0.5001], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7327, 0.7148, 0.5000, 0.5019], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7296, 0.7149, 0.5000, 0.5015], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7309, 0.7142, 0.5000, 0.4998], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7323, 0.7145, 0.5004, 0.5028], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7328, 0.7144, 0.5007, 0.5009], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7287, 0.7136, 0.4998, 0.4994], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7323, 0.7138, 0.4998, 0.5017], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7289, 0.7139, 0.4994, 0.5001], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7327, 0.7151, 0.4994, 0.4977], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7309, 0.7147, 0.4996, 0.4974], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7282, 0.7141, 0.4995, 0.5008], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "EPOCH 9\n",
      "tensor([0.6713, 0.7126, 0.4985, 0.5381], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7334, 0.7148, 0.5003, 0.5007], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7301, 0.7142, 0.4994, 0.4998], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7313, 0.7150, 0.5005, 0.5031], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7311, 0.7140, 0.4993, 0.5008], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7331, 0.7142, 0.4997, 0.4997], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7314, 0.7139, 0.4993, 0.4971], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([0.7301, 0.7146, 0.4999, 0.5018], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(200):\n",
    "    print(\"EPOCH %s\" % epoch)\n",
    "    loss_history = None\n",
    "    \n",
    "    for batch_index in range(int(VOX_COUNT/BATCH_SIZE)):\n",
    "        random_id_list = random.choices(pdb_ids, k=BATCH_SIZE)\n",
    "        \n",
    "        vox_batch_a, vox_batch_b = get_vox_batch(training_sample_dict, random_id_list)\n",
    "        mol_batch = get_mol_batch(mol_dict, random_id_list)\n",
    "\n",
    "        vox_a_interxn_i, vox_a_contact_i, mol_interxn_i, mol_a_contact_i = get_batch_indices(vox_batch_a, mol_batch) \n",
    "        vox_b_interxn_i, _, _, _ = get_batch_indices(vox_batch_b, mol_batch) \n",
    "\n",
    "        vox_embed_a, vox_pred_a = voxel_model(vox_batch_a.to(device))\n",
    "        vox_embed_b, vox_pred_b = voxel_model(vox_batch_b.to(device))\n",
    "        mol_embed, mol_pred, _ = mol_model(mol_batch.to(device))\n",
    "\n",
    "        atom_preds = torch.vstack((vox_pred_a[vox_a_interxn_i], vox_pred_b[vox_b_interxn_i]))\n",
    "        atom_labels = torch.vstack((vox_batch_a.y[vox_a_interxn_i], vox_batch_b.y[vox_b_interxn_i])).float()\n",
    "\n",
    "        l1 = criterion1(atom_preds, atom_labels)\n",
    "        l2 = criterion2(mol_pred[mol_interxn_i], mol_batch.y[mol_interxn_i])\n",
    "        l3 = criterion3(vox_embed_a[vox_a_contact_i], \n",
    "                   mol_embed[mol_a_contact_i],\n",
    "                   mol_embed[get_shuffled_mol_indices(mol_batch)[mol_a_contact_i]])\n",
    "\n",
    "        l4 = criterion4(mol_embed[mol_a_contact_i], vox_embed_a[vox_a_contact_i], vox_embed_b[vox_a_contact_i])\n",
    "        \n",
    "#         loss = l1+l2+5*l3+5*l4\n",
    "        loss = l3+l4\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        v_optimizer.step()\n",
    "        m_optimizer.step()\n",
    "        \n",
    "        l_tensor = torch.hstack([l1,l2,l3,l4]).unsqueeze(0)\n",
    "        \n",
    "        if loss_history is None:\n",
    "            loss_history = l_tensor\n",
    "        else:\n",
    "            loss_history = torch.vstack((loss_history, l_tensor))\n",
    "            \n",
    "        if batch_index % 1000 == 0:\n",
    "            print(torch.mean(loss_history, dim=0))\n",
    "            loss_history = l_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample_col' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [123], line 46\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m h,o\n\u001b[1;32m     44\u001b[0m voxel_model \u001b[38;5;241m=\u001b[39m GCN(\u001b[38;5;241m39\u001b[39m, \u001b[38;5;241m512\u001b[39m, \u001b[38;5;241m9\u001b[39m, data_transform\u001b[38;5;241m=\u001b[39mhandle_data)\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sample_file \u001b[38;5;129;01min\u001b[39;00m \u001b[43msample_col\u001b[49m:\n\u001b[1;32m     47\u001b[0m     sample_collection \u001b[38;5;241m=\u001b[39m DataLoader(pickle\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mopen\u001b[39m(sample_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m)), batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m sample_collection:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sample_col' is not defined"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import GATv2Conv\n",
    "from torch_geometric.nn import GCN2Conv\n",
    "\n",
    "def handle_data(batch):\n",
    "    beta = batch.beta/100 \n",
    "    x = torch.hstack((batch.x, beta.unsqueeze(1)))\n",
    "    edge_attr = batch.edge_attr.unsqueeze(1) / 12\n",
    "    return x, batch.edge_index, edge_attr\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, feature_dim, hidden_dim, out_dim, data_transform):\n",
    "        super().__init__()\n",
    "        self.data_transform = data_transform\n",
    "        self.linear1 = torch.nn.Linear(feature_dim, hidden_dim)\n",
    "        \n",
    "        self.conv1 = GCN2Conv(hidden_dim, 0.25)\n",
    "        self.conv2 = GCN2Conv(hidden_dim, 0.25)\n",
    "        self.conv3 = GCN2Conv(hidden_dim, 0.25)\n",
    "\n",
    "        self.dropout = torch.nn.Dropout(p=0.25)\n",
    "        self.batchnorm = torch_geometric.nn.norm.BatchNorm(hidden_dim)\n",
    "        self.linear2 = torch.nn.Linear(hidden_dim, out_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_weights = self.data_transform(data)\n",
    "\n",
    "        x = self.linear1(x)\n",
    "\n",
    "        h = self.conv1(x, x, edge_index, edge_weights)\n",
    "        h = self.batchnorm(h)\n",
    "        h = self.dropout(F.relu(h))\n",
    "\n",
    "        h = self.conv2(h, x, edge_index, edge_weights)\n",
    "        h = self.batchnorm(h)\n",
    "        h = self.dropout(F.relu(h))\n",
    "\n",
    "        h = self.conv3(h, x, edge_index, edge_weights)\n",
    "        h = self.batchnorm(h)\n",
    "        h = self.dropout(F.relu(h))\n",
    "        \n",
    "        o = self.linear2(h)\n",
    "        return h,o\n",
    "\n",
    "voxel_model = GCN(39, 512, 9, data_transform=handle_data)\n",
    "\n",
    "for sample_file in sample_col:\n",
    "    sample_collection = DataLoader(pickle.load(open(sample_file, 'rb')), batch_size=32, shuffle=True)\n",
    "    \n",
    "    for batch in sample_collection:\n",
    "        out = voxel_model(batch)\n",
    "        print(out[0].shape)\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import AttentiveFP\n",
    "from torch_geometric.nn import GATConv, MessagePassing, global_add_pool\n",
    "\n",
    "class ME(AttentiveFP):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.atom_classifier = nn.Linear(kwargs['hidden_channels'], 512)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
    "        \"\"\"\"\"\"\n",
    "        # Atom Embedding:\n",
    "        x = F.leaky_relu_(self.lin1(x))\n",
    "\n",
    "        h = F.elu_(self.atom_convs[0](x, edge_index, edge_attr))\n",
    "        h = F.dropout(h, p=self.dropout, training=self.training)\n",
    "        x = self.atom_grus[0](h, x).relu_()\n",
    "\n",
    "        for conv, gru in zip(self.atom_convs[1:], self.atom_grus[1:]):\n",
    "            h = F.elu_(conv(x, edge_index))\n",
    "            h = F.dropout(h, p=self.dropout, training=self.training)\n",
    "            x = gru(h, x).relu_()\n",
    "\n",
    "        # Molecule Embedding:\n",
    "        row = torch.arange(batch.size(0), device=batch.device)\n",
    "        edge_index = torch.stack([row, batch], dim=0)\n",
    "\n",
    "        out = global_add_pool(x, batch).relu_()\n",
    "        \n",
    "        for t in range(self.num_timesteps):\n",
    "            h = F.elu_(self.mol_conv((x, out), edge_index))\n",
    "            h = F.dropout(h, p=self.dropout, training=self.training)\n",
    "            out = self.mol_gru(h, out).relu_()\n",
    "\n",
    "        # Predictor:\n",
    "        out = F.dropout(out, p=self.dropout, training=self.training)\n",
    "        return self.atom_classifier(x), self.lin2(out)\n",
    "    \n",
    "mol_model = ME(in_channels=38, \n",
    "               hidden_channels=512, \n",
    "               out_channels=512, \n",
    "               edge_dim=1, \n",
    "               num_layers=3, \n",
    "               num_timesteps=3, \n",
    "               dropout=0.5)\n",
    "\n",
    "for batch in sample_collection:\n",
    "    mol_batch = get_mol_batch(mol_dict, batch.pdb_id)\n",
    "    print(torch.where(mol_batch.heavy == 1)[0][torch.randperm(torch.sum(mol_batch.heavy))][:10])\n",
    "    break\n",
    "    print(mol_batch.ptr)\n",
    "    out = mol_model(mol_batch)\n",
    "    print(out[0].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device='cpu'\n",
    "\n",
    "mol_weights = \"/xdisk/twheeler/jgaiser/deepvs2/contrastive_loss_exp/mol_embedder/mol_embedder_holdout_3-20.m\"\n",
    "vox_weights = \"/xdisk/twheeler/jgaiser/deepvs2/contrastive_loss_exp/vox_embedder/vox_embedder_holdout_3-20.m\"\n",
    "\n",
    "mol_model = ME(in_channels=38, \n",
    "               hidden_channels=512, \n",
    "               out_channels=512, \n",
    "               edge_dim=1, \n",
    "               num_layers=3, \n",
    "               num_timesteps=3, \n",
    "               dropout=0.5).to(device)\n",
    "\n",
    "vox_model = GCN(39, 512, 9, data_transform=handle_data).to(device)\n",
    "\n",
    "mol_model.load_state_dict(torch.load(mol_weights))\n",
    "vox_model.load_state_dict(torch.load(vox_weights))\n",
    "\n",
    "EPOCHS = 1000\n",
    "triplet_loss1 = TripletMarginLoss(margin=1.0, p=2).to(device)\n",
    "triplet_loss2 = TripletMarginLoss(margin=1.0, p=2).to(device)\n",
    "v_optimizer = torch.optim.Adam(vox_model.parameters(), lr=1e-6)\n",
    "m_optimizer = torch.optim.Adam(mol_model.parameters(), lr=1e-6)\n",
    "\n",
    "min_loss = 999\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(\"EPOCH %s\" % epoch)\n",
    "    epoch_loss = []\n",
    "    \n",
    "    for sample_file in sample_col:\n",
    "        sample_file = pickle.load(open(sample_file, 'rb'))\n",
    "        filtered_sample_graphs = []\n",
    "        \n",
    "        for sample_graph in sample_file:\n",
    "            if sample_graph.pdb_id not in holdout_complexes:\n",
    "                filtered_sample_graphs.append(sample_graph)\n",
    "            \n",
    "        sample_collection = DataLoader(filtered_sample_graphs, batch_size=64, shuffle=True)\n",
    "        sample_col_loss1 = []\n",
    "        sample_col_loss2 = []\n",
    "        sample_col_loss = []\n",
    "\n",
    "        for batch_i, vox_batch in enumerate(sample_collection):\n",
    "            vox_batch = vox_batch.to(device)\n",
    "            mol_batch = get_mol_batch(mol_dict, vox_batch.pdb_id).to(device)\n",
    "            voxel_indices = torch.where(vox_batch.x[:, voxel_label_index]==1)[0]\n",
    "\n",
    "            true_contacts = torch.where(vox_batch.contact_map != -1)[0]\n",
    "            contact_indices = vox_batch.contact_map + mol_batch.ptr[:-1]\n",
    "\n",
    "            contact_indices = contact_indices[true_contacts]\n",
    "            voxel_indices = voxel_indices[true_contacts]\n",
    "            shuffled_voxel_indices = voxel_indices[torch.randperm(voxel_indices.size(0))]\n",
    "            \n",
    "#             random_mol_indices = torch.randint(0, mol_batch.x.size(0), (true_contacts.size(0),))\n",
    "            random_mol_indices = torch.where(mol_batch.heavy == 1)[0]\n",
    "            random_mol_indices = random_mol_indices[torch.randperm(torch.sum(mol_batch.heavy))]\n",
    "            random_mol_indices = random_mol_indices[:true_contacts.size(0)]\n",
    "\n",
    "            vox_out,_ = vox_model(vox_batch)\n",
    "            mol_out,_ = mol_model(mol_batch)\n",
    "            \n",
    "            loss1 = triplet_loss1(vox_pos, mol_pos, mol_neg)\n",
    "            loss2 = triplet_loss2(mol_pos, vox_pos, vox_neg)\n",
    "            loss = loss1+loss2\n",
    "            \n",
    "            sample_col_loss1.append(loss1.item())\n",
    "            sample_col_loss2.append(loss2.item())\n",
    "            sample_col_loss.append(loss.item())\n",
    "            loss.backward()\n",
    "            v_optimizer.step()\n",
    "            m_optimizer.step()\n",
    "\n",
    "        avg_col_loss1 = sum(sample_col_loss1) / len(sample_col_loss1)\n",
    "        avg_col_loss2 = sum(sample_col_loss2) / len(sample_col_loss2)\n",
    "        avg_col_loss = sum(sample_col_loss) / len(sample_col_loss)\n",
    "        \n",
    "        if avg_col_loss==avg_col_loss:\n",
    "            epoch_loss.append(avg_col_loss)\n",
    "            \n",
    "        print(avg_col_loss1, avg_col_loss2, avg_col_loss)\n",
    "\n",
    "    avg_epoch_loss = sum(epoch_loss)/len(epoch_loss)\n",
    "    print(\"Epoch %s loss: %s\" % (epoch, avg_epoch_loss))\n",
    "    \n",
    "    if avg_epoch_loss < min_loss:\n",
    "        min_loss = avg_epoch_loss\n",
    "        torch.save(mol_model.state_dict(), mol_weights)\n",
    "        torch.save(vox_model.state_dict(), vox_weights)\n",
    "        print(\"Weights Updated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mol_model.state_dict(), mol_weights)\n",
    "torch.save(vox_model.state_dict(), vox_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = float('nan')\n",
    "num==num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "mol_model = ME(in_channels=38, \n",
    "               hidden_channels=512, \n",
    "               out_channels=512, \n",
    "               edge_dim=1, \n",
    "               num_layers=3, \n",
    "               num_timesteps=3, \n",
    "               dropout=0.5).to(device)\n",
    "\n",
    "vox_model = GCN(39, 512, 9, data_transform=handle_data).to(device)\n",
    "\n",
    "mol_model.load_state_dict(torch.load(mol_weights))\n",
    "vox_model.load_state_dict(torch.load(vox_weights))\n",
    "\n",
    "mol_model.eval()\n",
    "vox_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for sample_file in sample_col:\n",
    "        sample_collection = DataLoader(pickle.load(open(sample_file, 'rb')), batch_size=64, shuffle=True)\n",
    "        sample_col_loss = []\n",
    "\n",
    "        for batch_i, vox_batch in enumerate(sample_collection):\n",
    "            vox_batch = vox_batch.to(device)\n",
    "            mol_batch = get_mol_batch(mol_dict, vox_batch.pdb_id).to(device)\n",
    "            voxel_indices = torch.where(vox_batch.x[:, voxel_label_index]==1)[0]\n",
    "\n",
    "            vox_out,_ = vox_model(vox_batch)\n",
    "            mol_out,_ = mol_model(mol_batch)\n",
    "            \n",
    "            print(vox_out[0])\n",
    "            \n",
    "            break\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepvs-env",
   "language": "python",
   "name": "deepvs-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
